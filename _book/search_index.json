[
["introduction.html", "Analysis of Trip Advisor data relating to South Australian parks 1 Introduction", " Analysis of Trip Advisor data relating to South Australian parks Department for Environment and Water Thursday, 13 June, 2019 1 Introduction DEW manages many parks across South Australia. Some of these parks have a ‘page’ on TripAdvisor. For example, there is a page for Ikara-Flinders Ranges National Park. DEW are interested to know what information is contained in TripAdvisor reviews. Specifically, the following questions were identified by the community engagement branch: Where are visitors from: Overall percentages – as in, of all the people who reviewed SA parks, 40 percent were Australian, 10 percent were English, 8 percent were American etc. By park percentages – as in, of all the people who reviewed Belair National Park, 40 percent were Australian, 10 percent were English, 8 percent were American etc. What gender are visitors: Overall percentages – as in, of all the people who reviewed SA parks, 45 percent were male and 55 percent were female By park percentages – as in, of all the people who reviewed Belair national park, 45 percent were male and 55 percent were female What ages are visitors? Overall By individual park When are reviews made? (As in, in which month is the quantity of reviews submitted to Trip Advisor the highest? In which month is the quantity of reviews submitted to Trip Advisor the lowest?) Overall By individual park How does seasonality affect park ratings? (As in, parks receive most positive ratings in December and most negative ratings in May) Overall By individual park Are males or females more likely to rate parks positively or negatively? Overall By individual park Which country/state is more likely to rate parks positively or negatively? Overall By individual park Which age is more likely to rate parks positively or negatively? Overall By individual park Other possible questions SA analysis – Adelaide vs regional views of parks Multiple park reviews from one user: Does reviewing more than one park lead to higher or lower ratings? What parks are visited by people who review more than one park? Can we get a sense of itinerary from international visitors? After an initial data exploration, these questions were treated as the following: What is the effect of age and gender on the rating given? What is the effect of the park visited on the rating given? What is the effect of the origin of a reviewer on the rating given? These three analyses answer most of the questions posed by the community engagement branch but do not always examine interations, such as, say, the interaction of age and park on stars. This was done as sample size was very small for some groups, especially for low stars. A further analysis of words used in the titles and reviews was also undertaken. "],
["methods.html", "2 Methods 2.1 Data source 2.2 Workflow", " 2 Methods 2.1 Data source Data were taken from Trip Advisor. The site is one of the most popular sources of reviews for hotels, restaurants, experiences, attractions and places such as parks. Trip Advisor features user-generated content with 315 million reviewers (active and inactive) and about 500 million reviews Wikipedia. For the purposes of this analysis, the search function in Trip Advisor was used to identify all parks, reserves and features in parks and reserves that have been reviewed. Some reviews were captured under a park name, such as “Flinders Chase National Park” and some were captured under a feature name, such as “Flinders Chase Visitor Centre”. The web scraping software Octoparse was used to capture the following elements for analysis: Reviewer name Reviewer location (country, state and city) Reviewer age Reviewer gender Review date Review title Review text Review star rating Note that the web scraping software was able to effectively capture elements such as name, date, title, text and star rating, but that capturing the demographic information about the reviewers was a more difficult process. The demographic information is contained within “hover over” elements of the Trip Advisor web pages. Code was written to scrape these elements for the initial data scrape; manual cutting and pasting was used for scrape updates. It may be for this reason that most academic analysis of Trip Advisor reviews does not extend to considering demographic information and that this report may offer some new information about the utility of this data source. Once the data was captured it was cleaned so that it could be more easily used for qualitative analysis. The cleaning included: Ensuring that each review was attached to a unique reviewer name Standardising place names to ensure that spellings were correct Allocating state and/or countries to reviewers who gave only partial location information such as city of residence Ensuring that the data set contained no blank cells Removing reviewers under 18 years old (remove reviewers where the age field was equal to 13-17) 2.2 Workflow This data analysis and report writing was done in a single scripted workflow (script file: Report.Rmd using the programs ‘R’ and ‘R-studio’. R (R Core Team 2019) is an open-source platform which makes available a library of packages that can be used and modified as necessary. R-studio provides a range of user-friendly features to facilitate interaction with R. The packages used are listed in the appendix: R packages used Table 9.6. All data, code and outputs are stored in a version control system at Parks_Trip-Advisor. References "],
["data-exploration.html", "3 Data exploration 3.1 Summary 3.2 Missing data 3.3 Count of reviews", " 3 Data exploration 3.1 Summary Between NA and NA there were 10987 reviews on TripAdvisor meeting the criteria outline in the methods. 3.2 Missing data Some of the key data fields were left blank in many reviews. For example, 5028 (46%) reviews did not provide their gender and 5833 (53%) didn’t provide their age. Figure 3.1 shows the percentage of reviews that did not provide information against each field. Figure 3.1: A large proportion of reviews did not answer some questions, particularly Gender and Age 3.3 Count of reviews There are several variables in the data with relatively few levels: Age; City; Country; Feature/location; Gender; id; Month; Origin; Park; reviews; Stars; State; Text; User; and Year. Figure 3.2 shows the most frequently occuring values in each of those variables. Figure 3.2: Most frequent values in each of the variables. Most reviews were from Adelaide based 50-64 year olds called Charmaine who visited Flinders Chase in January 2016 and gave it 5 stars "],
["model-of-stars-rating.html", "4 Model of stars (rating) 4.1 Model 4.2 Model diagnostics 4.3 Model predictions", " 4 Model of stars (rating) 4.1 Model The effect of age, gender and year of review on the stars given were analysed using a Bayesian binomial generalised linear mixed model. The analysis was run using the rstanarm package (Stan Development Team 2016) in R (R Core Team 2019). Park (visited by reviewer) and Origin (of reviewer - state if reviewer was from Australia or country if not) were treated as random effects in the analysis. The Feature/location field was ignored for this analysis. The model specification was: cbind(Y, 4 - Y) ~ time * Gender * Age + (time | Park) + (time | , Origin) where Y is Stars-1. This required the model to estimate 74 parameters. 4.2 Model diagnostics Figure 4.1 shows that each of the chains used to estimate model parameters converged around similar values for each parameter. Figure 4.1: All chains converged around the same values for each of the model paramaters (first 10 shown here) Figure 4.2 provides further support for convergence of the chains as no values are markedly different to 1.0. Figure 4.2: Rhat values show no reason for concern Figure 4.3 shows how (a sample of) the model runs (in light blue) compare with the original data (shown in dark blue). Figure 4.3: The model runs under estimate four stars and over estimate three stars relative to the data Figure 4.4 shows how the mean and standard deviation of the model runs (in light blue) compare with that of the original data (in dark blue). Figure 4.4: Collectively the model runs do a reasonable job estimating the data 4.3 Model predictions 4.3.1 Age and gender In order to better understand how the data and resulting model are able to inform management, a number (4000) of simulations were made based on the model results (strictly, draws were made from the posterior predictive distribution). Each simulation generated a prediction based on a single draw of the model parameters from their predicted distributions. Table 4.1 shows a summary of these results. Figure 4.5 shows a plot of the model results. Overwhelmingly, reviewers give 5 stars, irrespective of age or gender. Table 4.1: Summary of model results Year Age Gender Mean Median and range in 90% credible intervals 2019 18-24 Female 4.37 5 (3 to 5) 2019 18-24 Male 4.06 4 (2 to 5) 2019 25-34 Female 4.80 5 (4 to 5) 2019 25-34 Male 4.48 5 (3 to 5) 2019 35-49 Female 4.62 5 (3 to 5) 2019 35-49 Male 4.63 5 (3 to 5) 2019 50-64 Female 4.62 5 (3 to 5) 2019 50-64 Male 4.65 5 (3 to 5) 2019 65+ Female 4.66 5 (3 to 5) 2019 65+ Male 4.48 5 (3 to 5) Figure 4.5: Most reviewers give 5 stars irrespective of age or gender. Line is mean credible estimate and shading is 95% credible intervals. The lower 95% credible intervals go to three stars in almost every case - i.e. more than 95% of responses are three stars or more. Dots are original data points (jittered for clarity) 4.3.2 Park Table 4.2 shows a summary of predicted results for each Park. These results assume a population of reviewers split evenly among the levels of age, gender and year of review. Figure 4.6 shows a plot of the results for each park. Table 4.2: Summary of model results for the last year with data. Cleland Conservation Park and Far West Coast Marine Park have the highest ratings (based on mean credible estimates) Park Year Mean Median and range in 90% credible intervals Cleland Conservation Park 2019 4.59 5 (3 to 5) Far West Coast Marine Park 2019 4.59 5 (3 to 5) Ikara-Flinders Ranges National Park 2019 4.58 5 (3 to 5) Naracoorte Caves National Park 2019 4.55 5 (3 to 5) Cleland Wildlife Park 2019 4.54 5 (3 to 5) Flinders Chase National Park 2019 4.54 5 (3 to 5) Granite Island 2019 4.54 5 (3 to 5) Mount Lofty Summit 2019 4.54 5 (3 to 5) Seal Bay Conservation Park 2019 4.54 5 (3 to 5) Other 2019 4.54 5 (3 to 5) Breakaways Conservation Park 2019 4.53 5 (3 to 5) Figure 4.6: Line is mean credible estimate and shading is 95% credible intervals. Dots are original data points (jittered for clarity) 4.3.3 Origin Table 4.3 shows a summary of results for the origin of the reviewer. These results assume a population of reviewers split evenly among the levels of age, gender and year of review. Figure 4.7 shows a plot of the results for each park. Table 4.3: Summary of model results for the last year with data. Canada and India have the highest ratings (based on mean credible estimates) Origin Year Mean Median and range in 90% credible intervals Canada 2019 4.64 5 (3 to 5) India 2019 4.63 5 (3 to 5) China 2019 4.59 5 (3 to 5) New Zealand 2019 4.59 5 (3 to 5) Queensland 2019 4.59 5 (3 to 5) United States 2019 4.59 5 (3 to 5) Northern Territory 2019 4.58 5 (3 to 5) Tasmania 2019 4.58 5 (3 to 5) Australian Capital Territory 2019 4.56 5 (3 to 5) Singapore 2019 4.55 5 (3 to 5) New South Wales 2019 4.53 5 (3 to 5) South Australia 2019 4.53 5 (3 to 5) United Kingdom 2019 4.53 5 (3 to 5) Victoria 2019 4.53 5 (3 to 5) Western Australia 2019 4.53 5 (3 to 5) Malaysia 2019 4.52 5 (3 to 5) Figure 4.7: Line is mean credible estimate and shading is 95% credible intervals. Dots are original data points (jittered for clarity) References "],
["word-analysis.html", "5 Word analysis 5.1 Overall sentiment 5.2 By park sentiment", " 5 Word analysis 5.1 Overall sentiment Using the tidytext package (Robinson and Silge 2018), the text within the character fields Title and Review were analysed. Some words were replaced with a synonym (Appendix Table 9.1). This includes ‘lumping’ words such as, say, echidna into wildlife. The following words were reclassified as neutral from negative sentiment as they were overwhelmingly not used in a negative manner: cave; challenging; cold; crashing; desert; dirt; downhill; falls; miss; remarkable; rocky; ruins; shady; steep; unbelievable; unexpected; unusual; wedge; and wild. The following words were removed from the analysis as they refer to park or place names, and occur frequently, but do not add much to the analysis: adelaide; arch; chase; coffin; coober; flinders; granite; gully; harbor; harbour; island; kangaroo; ki; lofty; morialta; mount; mt; national; park; pedy; pound; ranges; review; rocks; title; victor; and wilpena. Figure 5.1 shows the ten most common positive, negative and neutral words given in the combined Title and Review fields. The most frequent word with positive sentiment was worth. A random sample of contexts in which worth occured: Definitely worth the drive - Lighthouse tour with Rob a must! Fantastic well worth the visit Well worth the trip to see some amazing geology (and bats) Definitely worth the trip! A place worth the visit The most frequent word with neutral sentiment was nature. A random sample of contexts in which nature occured: “good spot to see nature/animals” Relatively easy walk experiencing all that nature has to offer. 9to5explorer: unbelievable bushland and nature, just 30mins from CBD 5* Live a day with the wonders of the nature “Beautifull nature” The most frequent word with negative sentiments was expensive. A random sample of contexts in which expensive occurred: A little expensive considering Special but expensive. Nice to see the seals but expensive Bit expensive but good Too expensive for a walk on a beach Figure 5.1: Titles had words with positive sentiment much more frequently than words with negative sentiment 5.2 By park sentiment Figure 5.2 shows, by park, the five most common positive, negative and neutral words given in the combined Title and Review fields. Most parks had beautiful in their positive words, for example: “Breathtakingly beautiful” beautiful walk, beautiful island “beautiful retreat” Wild and beautiful “beautiful Gully” Most parks had hard in their negative words, for example: “Amazing rocks and interesting park with abundant wildlife which is hard to see” a pretty walk, choose easy or hard Really hard work on this trail but you feel so much better when you get there Pretty yet hard work. Great view but whales were hard to see. Figure 5.2: Top ten words in each sentiment class (positive, negative and neutral) for the parks with the most reviews References "],
["activities.html", "6 Activities 6.1 Overall activities 6.2 Activities by park", " 6 Activities These activities were searched for in the combined Title and Review fields: 4wding; birding; boating; campfire; camping; caving; cycling; diving; dog; dolphin; fish; geocaching; horse riding; kayaking; orienteering; rock climbing; snorkelling; surfing; swimming; tennis; tour; walking; waterskiing; and whale. Appendix Table 9.2 shows which words were treated as synonyms for each activity. 6.1 Overall activities Figure 6.1 shows how frequently each of those activities were mentioned overall. Figure 6.1: camping, tour and walking are the most popular activities mentioned in reviews 6.2 Activities by park Figure 6.2 shows, by activity, how frequently each of those activities were mentioned for the most visited parks. Figure 6.3 shows, by park, how frequently each of those activities were mentioned for the most visited parks. See appendix Table 9.3 for the full list of parks and activities. Figure 6.2: Top 10 activities - frequency within park Figure 6.3: Top 10 parks - frequency of activities within park "],
["facilities.html", "7 Facilities 7.1 Overall facilities 7.2 Facilities by park", " 7 Facilities These facilities were searched for in the combined Title and Review fields: bbq; campsite; carpark; phone coverage; picnic; playground; public transport; road; shower; sign; toilet; tracks; water; and website. Appendix Table 9.4 shows which words were treated as synonyms for each type of facility. The sentiment of the sentence in which facilities were mentioned was determined using the AFINN lexicon (Nielsen 2011), provided by the tidytext package (Robinson and Silge 2018). 7.1 Overall facilities Figure 7.1 shows how frequently each facility was mentioned, including the sentiment of the sentence in which the facility was mentioned. Figure 7.1: Facilities most frequently mentioned in reviews and the sentiment of the sentence in which they occur 7.2 Facilities by park Figure 7.2 shows, by park, how frequently each facility was mentioned for the most visited parks, including the sentiment of the sentence in which the facility was mentioned. See appendix Table 9.5 for the full list of parks and facilities. Figure 7.2: Top 10 parks - frequency of facilities within park References "],
["discussion.html", "8 Discussion 8.1 Questions 8.2 Words used in reviews 8.3 Activities 8.4 Facilities", " 8 Discussion 8.1 Questions It is now possible to answer the questions posed at the start with respect to the TripAdvisor data. 8.1.1 What is the effect of age and gender on the rating given? There was very little effect of age and gender on stars. 18-24 year old males had the lowest mean credible estimate for stars but this was still a relatively healthy 4.06 stars. 8.1.2 What is the effect of the park visited on the rating given? There was little effect of park on the rating given. In the last year there was only 0.06 stars difference between the maximum and minimum mean credible estimate for stars given to parks in the dataset. This is only 1.2% of the possible range of 1 to 5. 8.1.3 What is the effect of the origin of a reviewer on the rating given? There was very little effect of the origin of a reviewer on the rating given. In the last year, there was only 0.12 stars or 2.4% of the possible difference. 8.1.4 Summary The TripAdvisor data has little resolution in stars given for the attributes available for analysis. Most reviewers give South Australian DEW managed parks very good reviews - roughly 4.6 stars on average. 8.2 Words used in reviews As for the stars analysis, the word analysis showed overwhelmingly positive words were used to describe both overall parks (e.g. Figure 5.1 and specific parks Figures 5.2). Reviewers most frequently mentioned nature; walk; and wildlife in their reviews along with positive words such as amazing; beautiful; enjoy; nice; and worth. 8.3 Activities The most popular activities in parks (and % of reviews in which the activity was mentioned) were: camping: 5.8% tour: 24.8% walking: 45% 8.4 Facilities The faciltities most mentioned in reviews (and % of reviews in which the activity was mentioned) were: public transport: 9.8% road: 11.9% tracks: 13.4% "],
["appendix.html", "9 Appendix 9.1 Changed words 9.2 Activities 9.3 Facilities 9.4 R packages used", " 9 Appendix 9.1 Changed words Table 9.1: Words that were changed to a synonym before further analysis word changed disappointing dissapoint disappointed dissapoint disappointment dissapoint colours colour color colour beauty beautiful enjoyed enjoy loved love sadly sad difficulty difficult crowded crowd limits limit beaches beach cycling cycle cycled cycle cyclists cycle riding cycle rides cycle mtb cycle bike cycle rode cycle walking walk walked walk walks walk stroll walk strolling walk hiking walk hiked walk hike walk camping camp camped camp driving drive drove drive penguin wildlife penguins wildlife fur wildlife seal wildlife seals wildlife koala wildlife koalas wildlife kangaroos wildlife echidna wildlife platypus wildlife bird wildlife birds wildlife wallabies wildlife emu wildlife emus wildlife animals wildlife lions wildlife sealions wildlife landscape nature view nature views nature scenery nature scenic nature natural nature breakaways nature remarkable nature admirals nature waterfall nature falls nature waterfalls nature lighthouse heritage ruin heritage 9.2 Activities Table 9.2: Activities and associated synonyms, including regular expression syntax used in searches. e.g. ‘.?’ means match a space zero or one time; (?!…) is a negative lookaround (e.g. used for find ‘dog’ without ‘fence’) Type Use Find activity 4wding 4.?wd activity 4wding 4.?wheel.?drive activity 4wding four.?wheel.?drive activity 4wding awd activity 4wding all.?wheel.?drive activity birding bird.?watching activity birding bird.?ing activity birding \\bbird\\b activity birding twitch activity boating boat activity boating sail activity campfire camp.?fire activity campfire fire.?wood activity camping tent activity camping camp activity caving caving activity caving speleology activity cycling \\bbike\\b activity cycling biked activity cycling biking activity cycling cycle activity cycling cycling activity cycling mountain.?biking activity cycling mountain.?bike activity cycling mtb activity diving \\bdive\\b activity diving dived activity diving diving activity diving scuba activity dog (?s)^(?=.dog)(?=.walk)(?!=.*fence) activity dolphin (?s)^(?=.dolphin)(?=.watch) activity dolphin (?s)^(?=.dolphin)(?=.view) activity fish fish activity geocaching geo.?cach activity horse riding horse.?riding activity kayaking canoe activity kayaking kayak activity orienteering orienteer activity rock climbing rock.?climb activity rock climbing abseil activity snorkelling snorkel activity surfing surf activity swimming swam activity swimming swum activity swimming swim activity tennis tennis activity tour tour activity walking bush.?walk activity walking hike activity walking hiked activity walking hiking activity walking walk activity waterskiing water.?ski activity whale (?s)^(?=.whale)(?=.watch) activity whale (?s)^(?=.whale)(?=.view) Table 9.3: Full list of activities and parks 9.3 Facilities Table 9.4: Facilities and associated synonyms, including regular expression syntax used in searches. e.g. ‘.?’ means match a space zero or one time Type Use Find facility bbq barbecue facility bbq barbeque facility bbq barbie facility bbq bbq facility campsite camp.?site facility carpark car.?park facility carpark parked facility phone coverage mobile.?coverage facility phone coverage phone.?coverage facility phone coverage phone.?reception facility phone coverage mobile.?reception facility picnic picnic facility playground play.?ground facility public transport bus facility public transport public transport facility public transport train facility road road facility shower shower facility sign sign facility toilet toilet facility tracks track facility tracks trail facility water drinking.?water facility water tap.?water facility website parks\\.sa\\.gov\\.au facility website web.?site Table 9.5: Full list of facilities and parks 9.4 R packages used Table 9.6: R (R Core Team 2019) packages used in the production of this report Package Citation base R Core Team (2019) bookdown Xie (2018) DT Xie et al. (2018) fs Hester and Wickham (2019) ggridges Wilke (2018) knitr Xie (2019) lubridate Spinu et al. (2018) readxl Wickham and Bryan (2019) rstan Guo et al. (2018) rstanarm Gabry and Goodrich (2018) tidytext Robinson and Silge (2018) tidyverse Wickham (2017) References "],
["references.html", "10 References", " 10 References "]
]
