[
["introduction.html", "Analysis of Trip Advisor data relating to South Australian parks 1 Introduction", " Analysis of Trip Advisor data relating to South Australian parks Department for Environment and Water Tuesday, 11 June, 2019 1 Introduction DEW manages many parks across South Australia. Some of these parks have a ‘page’ on TripAdvisor. For example, there is a page for Ikara-Flinders Ranges National Park. DEW are interested to know what information is contained in TripAdvisor reviews. Specifically, the following questions were identified by the community engagement branch: Where are visitors from: Overall percentages – as in, of all the people who reviewed SA parks, 40 percent were Australian, 10 percent were English, 8 percent were American etc. By park percentages – as in, of all the people who reviewed Belair National Park, 40 percent were Australian, 10 percent were English, 8 percent were American etc. What gender are visitors: Overall percentages – as in, of all the people who reviewed SA parks, 45 percent were male and 55 percent were female By park percentages – as in, of all the people who reviewed Belair national park, 45 percent were male and 55 percent were female What ages are visitors? Overall By individual park When are reviews made? (As in, in which month is the quantity of reviews submitted to Trip Advisor the highest? In which month is the quantity of reviews submitted to Trip Advisor the lowest?) Overall By individual park How does seasonality affect park ratings? (As in, parks receive most positive ratings in December and most negative ratings in May) Overall By individual park Are males or females more likely to rate parks positively or negatively? Overall By individual park Which country/state is more likely to rate parks positively or negatively? Overall By individual park Which age is more likely to rate parks positively or negatively? Overall By individual park Other possible questions SA analysis – Adelaide vs regional views of parks Multiple park reviews from one user: Does reviewing more than one park lead to higher or lower ratings? What parks are visited by people who review more than one park? Can we get a sense of itinerary from international visitors? After an initial data exploration, these questions were treated as the following: What is the effect of age and gender on the rating given? What is the effect of the park visited on the rating given? What is the effect of the origin of a reviewer on the rating given? These three analyses answer most of the questions posed by the community engagement branch but do not always examine interations, such as, say, the interaction of age and park on stars. This was done as sample size was very small for some groups, especially for low stars. A further analysis of words used in the titles and reviews was also undertaken. "],
["methods.html", "2 Methods 2.1 Data source 2.2 Workflow", " 2 Methods 2.1 Data source Data were taken from Trip Advisor. The site is one of the most popular sources of reviews for hotels, restaurants, experiences, attractions and places such as parks. Trip Advisor features user-generated content with 315 million reviewers (active and inactive) and about 500 million reviews Wikipedia. For the purposes of this analysis, the search function in Trip Advisor was used to identify all parks, reserves and features in parks and reserves that have been reviewed. Some reviews were captured under a park name, such as “Flinders Chase National Park” and some were captured under a feature name, such as “Flinders Chase Visitor Centre”. In order to manage the scope of this analysis it was decided to collect reviews in the first instance for parks that were reviewed under their official park names. Where there was a park that is of importance to DEW that had reviews under a feature name rather than a park name, these reviews were also collected. For example, reviews were collected for “Waterfall Gully” rather than for “Cleland Conservation Park”. A further current limitation, imposed to manage scope, was exclusion of “iconic sites”. The reviews available were cross referenced against a list of priority parks that DEW has identified through the parks characterisation project to ensure that reviews were captured for all significant non-iconic sites. The web scraping software Octoparse was used to capture the following elements for analysis: Reviewer name Reviewer location (country, state and city) Reviewer age Reviewer gender Review date Review title Review text Review star rating Note that the web scraping software was able to effectively capture elements such as name, date, title, text and star rating, but that capturing the demographic information about the reviewers was a more difficult process. The demographic information is contained within “hover over” elements of the Trip Advisor web pages. Code was written to scrape these elements for the initial data scrape; manual cutting and pasting was used for scrape updates. It may be for this reason that most academic analysis of Trip Advisor reviews does not extend to considering demographic information and that this report may offer some new information about the utility of this data source. Once the data was captured it was cleaned so that it could be imported into SPSS for quantitative analysis and Nvivo for qualitative analysis. The cleaning included: Ensuring that each review was attached to a unique reviewer name Standardising place names to ensure that spellings were correct Allocating state and/or countries to reviewers who gave only partial location information such as city of residence Ensuring that the data set contained no blank cells Removing reviewers under 18 years old (Age field equal to ‘13-18’) 2.2 Workflow This data analysis and report writing was done in a single scripted workflow (script file: Report.Rmd using the programs ‘R’ and ‘R-studio’. R (R Core Team 2019) is an open-source platform which makes available a library of packages that can be used and modified as necessary. R-studio provides a range of user-friendly features to facilitate interaction with R. The packages used are listed in the appendix: R packages used Table 8.4. All data, code and outputs are stored in a version control system at Parks_Trip-Advisor. References "],
["data-exploration.html", "3 Data exploration 3.1 Summary 3.2 Missing data 3.3 Count of reviews", " 3 Data exploration 3.1 Summary Between NA and NA there were 10987 reviews on TripAdvisor meeting the criteria outline in the methods. 3.2 Missing data Some of the key data fields were left blank in many reviews. For example, 5028 (46%) reviews did not provide their gender and 5833 (53%) didn’t provide their age. Figure 3.1 shows the percentage of reviews that did not provide information against each field. Figure 3.1: A large proportion of reviews did not answer some questions, particularly Gender and Age 3.3 Count of reviews There are several variables in the data with relatively few levels: Age; City; Country; Feature/location; Gender; id; Month; Origin; Park; reviews; Stars; State; Text; User; and Year. Figure 3.2 shows the most frequently occuring values in each of those variables. Figure 3.2: Most frequent values in each of the variables. Most reviews are from Adelaide based 50-64 year olds called Charmaine who visited Flinders Chase in January 2016 and gave it 5 stars "],
["age-and-gender.html", "4 Age and gender 4.1 Model 4.2 Model diagnostics 4.3 Model predictions", " 4 Age and gender 4.1 Model Trend through time (year) in stars given by age and gender of reviewers (and the interaction of age, gender and time) was analysed using a Bayesian binomial generalised linear mixed model. The analysis was run using the rstanarm package (Stan Development Team 2016) in R (R Core Team 2019). Month (of review), Park (visited by reviewer) and State (of origin of reviewer) were treated as random effects in the analysis. Each reviewer was then assumed to provide an independent data point for the analysis. A time field was generated as \\(time = min(Year) + (max(Year) - min(Year))/2\\). The model specification was: cbind(Y, 4 - Y) ~ time * Gender * Age + (time | Park) + (time | , Origin) where Y is Stars-1. 4.2 Model diagnostics Figure 4.1 shows that each of the chains used to estimate model parameters converged around similar values for each parameter. Figure 4.1: All chains converged around the same values for each of the model paramaters (first 10 shown here) Figure 4.2 provides further support for convergence of the chains as no values are markedly different to 1.0. Figure 4.2: Rhat values show no reason for concern Figure 4.3 shows how (a sample of) the model runs (in light blue) compare with the original data (shown in dark blue). Figure 4.3: The model runs under estimate four stars and over estimate three stars relative to the data Figure 4.4 shows how the mean and standard deviation of the model runs (in light blue) compare with that of the original data (in dark blue). Figure 4.4: Collectively the model runs do a reasonable job estimating the data 4.3 Model predictions 4.3.1 Age and gender In order to better understand how the data and resulting model are able to inform management, a number (4000) of simulations were made based on the model results (strictly, draws were made from the posterior predictive distribution). Each simulation generated a prediction based on a single draw of the model parameters from their predicted distributions. Table 4.1 shows a summary of these results. Table 4.1: Summary of model results Year Age Gender Mean Median and range in 90% credible intervals 2018 18-24 Male 4.20 4 (2 to 5) 2019 18-24 Female 4.34 5 (3 to 5) 2019 25-34 Female 4.80 5 (4 to 5) 2019 25-34 Male 4.47 5 (3 to 5) 2019 35-49 Female 4.63 5 (3 to 5) 2019 35-49 Male 4.62 5 (3 to 5) 2019 50-64 Female 4.63 5 (3 to 5) 2019 50-64 Male 4.65 5 (3 to 5) 2019 65+ Female 4.65 5 (3 to 5) 2019 65+ Male 4.44 5 (3 to 5) Figure 4.5 shows a plot of the model results. Overwhelmingly, reviewers give 5 stars, irrespective of age or gender. Figure 4.5: Model results - mean credible intervals. Most reviewers give 5 stars irrespective of age or gender. The lower 95% credible intervals go to three stars in almost every case - i.e. more than 95% of responses are three stars or more. Only for 18-24 year old males in 2015 do the 95% credible intervals go to 1 star 4.3.2 Park Table 4.2 shows a summary of predicted results for each Park, based on the ‘average’ age and gender of reviewers. Table 4.2: Summary of model results for the last year with data. Cleland Wildlife Park and Flinders Chase National Park have the highest ratings (based on mean credible estimates) Park Gender Year Mean Median and range in 90% credible intervals Cleland Wildlife Park Female 2019 4.65 5 (3 to 5) Flinders Chase National Park Female 2019 4.64 5 (3 to 5) Seal Bay Conservation Park Male 2019 4.64 5 (3 to 5) Granite Island Female 2019 4.63 5 (3 to 5) Seal Bay Conservation Park Female 2019 4.63 5 (3 to 5) Other Female 2019 4.63 5 (3 to 5) Other Male 2019 4.63 5 (3 to 5) Far West Coast Marine Park Female 2018 4.62 5 (3 to 5) Breakaways Conservation Park Male 2018 4.62 5 (3 to 5) Flinders Ranges National Park Female 2019 4.62 5 (3 to 5) Mount Lofty Summit Female 2019 4.62 5 (3 to 5) Naracoorte Caves National Park Female 2019 4.62 5 (3 to 5) Cleland Conservation Park Male 2019 4.62 5 (3 to 5) Flinders Chase National Park Male 2019 4.62 5 (3 to 5) Mount Lofty Summit Male 2019 4.62 5 (3 to 5) Flinders Ranges National Park Male 2018 4.61 5 (3 to 5) Breakaways Conservation Park Female 2019 4.61 5 (3 to 5) Granite Island Male 2019 4.61 5 (3 to 5) Naracoorte Caves National Park Male 2019 4.61 5 (3 to 5) Cleland Conservation Park Female 2018 4.60 5 (3 to 5) Cleland Wildlife Park Male 2019 4.60 5 (3 to 5) Far West Coast Marine Park Male 2017 4.58 5 (3 to 5) Figure 4.6: Model results - mean credible intervals. Belair and Point Labatt both seem to be getting increasingly negative reviews - although the mean credible estimate for both remains above 4 stars currently 4.3.3 Origin Table 4.3 shows a summary of these results. Table 4.3: Summary of model results for the last year with data. South Australia and Canada have the highest ratings (based on mean credible estimates) Origin Gender Year Mean Median and range in 90% credible intervals South Australia Female 2019 4.63 5 (3 to 5) Canada Male 2019 4.63 5 (3 to 5) South Australia Male 2019 4.63 5 (3 to 5) Victoria Male 2019 4.63 5 (3 to 5) United Kingdom Female 2018 4.62 5 (3 to 5) New South Wales Female 2019 4.62 5 (3 to 5) Victoria Female 2019 4.62 5 (3 to 5) Western Australia Female 2019 4.62 5 (3 to 5) New Zealand Male 2019 4.62 5 (3 to 5) Western Australia Male 2019 4.62 5 (3 to 5) New Zealand Female 2017 4.61 5 (3 to 5) Singapore Female 2017 4.61 5 (3 to 5) Canada Female 2018 4.61 5 (3 to 5) Queensland Female 2018 4.61 5 (3 to 5) Queensland Male 2018 4.61 5 (3 to 5) New South Wales Male 2019 4.61 5 (3 to 5) United States Male 2019 4.61 5 (3 to 5) United States Female 2017 4.60 5 (3 to 5) Australian Capital Territory Female 2018 4.60 5 (3 to 5) Northern Territory Male 2018 4.60 5 (3 to 5) Singapore Male 2018 4.60 5 (3 to 5) China Male 2017 4.59 5 (3 to 5) Malaysia Male 2018 4.59 5 (3 to 5) United Kingdom Male 2018 4.59 5 (3 to 5) China Female 2016 4.58 5 (3 to 5) Australian Capital Territory Male 2016 4.56 5 (3 to 5) Northern Territory Female 2014 4.55 5 (3 to 5) Tasmania Female 2014 4.55 5 (3 to 5) India Male 2015 4.55 5 (3 to 5) India Female 2014 4.54 5 (3 to 5) Malaysia Female 2014 4.54 5 (3 to 5) Figure 4.7: Model results - mean credible intervals. California and the North Island of New Zealand both appear to have increased the stars they give in reviews through time, however the total number of reviews are low in each case so this result should be treated cautiously. There is very little trend in stars given by origin of reviewers for other origins References "],
["word-analysis.html", "5 Word analysis 5.1 Overall sentiment 5.2 By park sentiment", " 5 Word analysis 5.1 Overall sentiment Using the tidytext package (Robinson and Silge 2018), the text within the character fields Title and Review were analysed. Some words were replaced with a synonym (Appendix Table 8.1). This includes ‘lumping’ words such as, say, echidna into wildlife. The following words were reclassified as neutral from negative sentiment as they were overwhelmingly not used in a negative manner: cave; challenging; cold; crashing; desert; dirt; downhill; falls; miss; remarkable; rocky; ruins; shady; steep; unbelievable; unexpected; unusual; wedge; and wild. The following words were removed from the analysis as they refer to park or place names, and occur frequently, but do not add much to the analysis: adelaide; arch; chase; coffin; coober; flinders; granite; gully; harbor; harbour; island; kangaroo; ki; lofty; morialta; mount; mt; national; park; pedy; pound; ranges; review; rocks; title; victor; and wilpena. Figure 5.1 shows the ten most common positive, negative and neutral words given in the combined Title and Review fields. The most frequent word with positive sentiment was worth. A random sample of contexts in which worth occured: Well worth experiencing Very Interesting, worth the travel to do this walk Beautiful location worth stopping for Wilpena Pound is worth the effort Definitely worth the drive out The most frequent word with neutral sentiment was nature. A random sample of contexts in which nature occured: Friendly advice to see nature at its best Rugged nature Another of nature’s sculptures Live a day with the wonders of the nature Great place to take in the views and appreciate nature The most frequent word with negative sentiments was expensive. A random sample of contexts in which expensive occurred: Mighty expensive but a great experience Good tour but expensive Quite expensive Naracoorte Caves too expensive! Guided beach visit - expensive but worth getting up closer to the seals. Figure 5.1: Titles had words with positive sentiment much more frequently than words with negative sentiment 5.2 By park sentiment Figure 5.2 shows, by park, the five most common positive, negative and neutral words given in the combined Title and Review fields. Most parks had beautiful in their positive words, for example: “Breathtakingly beautiful” Most beautiful lighthouse in Australia A beautiful and magical place A beautiful highly accessible cave. Fascinating from a scientific viewpoint with a beautiful view Most parks had hard in their negative words, for example: Great view but whales were hard to see. a pretty walk, choose easy or hard Really hard work on this trail but you feel so much better when you get there Pretty yet hard work. “Amazing rocks and interesting park with abundant wildlife which is hard to see” Figure 5.2: Top ten words in each sentiment class (positive, negative and neutral) for the parks with the most reviews References "],
["activities.html", "6 Activities", " 6 Activities These activities were searched for in the combined Title and Review fields: 4wding, birding, boating, campfire, camping, caving, cycling, diving, dog, dolphin, fishing, geocaching, horse riding, kayaking, orienteering, rock climbing, snorkelling, surfing, swimming, tennis, tour, walking, waterskiing, whale watching Appendix Table 8.2 shows which words were treated as synonyms for each activity. Figure 6.1 shows how frequently each of those activities were mentioned overall. Figure 6.2 shows how frequently each of those activities were mentioned for the most visited parks. See appendix Table 8.3 for the full list of parks and activities. Figure 6.1: concession, disabled, hard, issues, expensive, friendly, accessible, amazing, tour, worth, visit, beautiful, guide, caves and cave are by far the most popular activities mentioned in reviews Figure 6.2: The reviews provided for a park often spill over into surrounding activites. This explains, say, camping being an activity mentioned for Granite Island "],
["discussion.html", "7 Discussion 7.1 Questions 7.2 Words used in reviews 7.3 Activities", " 7 Discussion 7.1 Questions It is now possible to answer the questions posed at the start with respect to the TripAdvisor data. 7.1.1 What is the effect of age and gender on the rating given? There was very little effect of age and gender on stars. 18-24 year old males had the lowest mean credible estimate for stars but this was still a relatively healthy 4.2 stars. 7.1.2 What is the effect of the park visited on the rating given? There was little effect of park on the rating given. In the last year there was only 0.05 stars difference between the maximum and minimum mean credible estimate for stars given to parks in the dataset. This is only 1% of the possible range of 1 to 5. 7.1.3 What is the effect of the origin of a reviewer on the rating given? There was very little effect of the origin of a reviewer on the rating given. In the last year, there was only 0.02 stars or 0.4% of the possible difference. 7.1.4 Summary The TripAdvisor data has little resolution in stars given for the attributes available for analysis. Most reviewers give South Australian DEW managed parks very good reviews - roughly 4.5 stars on average. 7.2 Words used in reviews As for the stars analysis, the word analysis showed overwhelmingly positive words were used to describe both overall parks (e.g. Figure 5.1 and specific parks (Figures 5.2). Reviewers most frequently mentioned nature; walk; and wildlife in their reviews along with positive words such as amazing; beautiful; enjoy; nice; and worth. 7.3 Activities The most popular activities in parks (and % of reviews in which the activity was mentioned) were: paste0(activities %&gt;% dplyr::top_n(3,per) %&gt;% dplyr::pull(text),collapse = \"\\n* \") "],
["appendix.html", "8 Appendix 8.1 Changed words 8.2 Activities 8.3 R packages used", " 8 Appendix 8.1 Changed words Table 8.1: Words that were changed to a synonym before further analysis word changed disappointing dissapoint disappointed dissapoint disappointment dissapoint colours colour color colour beauty beautiful enjoyed enjoy loved love sadly sad difficulty difficult crowded crowd limits limit beaches beach cycling cycle cycled cycle cyclists cycle riding cycle rides cycle mtb cycle bike cycle rode cycle walking walk walked walk walks walk stroll walk strolling walk hiking walk hiked walk hike walk camping camp camped camp driving drive drove drive penguin wildlife penguins wildlife fur wildlife seal wildlife seals wildlife koala wildlife koalas wildlife kangaroos wildlife echidna wildlife platypus wildlife bird wildlife birds wildlife wallabies wildlife emu wildlife emus wildlife animals wildlife lions wildlife sealions wildlife landscape nature view nature views nature scenery nature scenic nature natural nature breakaways nature remarkable nature admirals nature waterfall nature falls nature waterfalls nature lighthouse heritage ruin heritage 8.2 Activities Table 8.2: Activities and associated synonyms. ‘.?’ means match a space zero or one time. (?!…) is a negative lookahead (e.g. find ‘dog’ without ‘fence’) Type Use Find activity 4wding 4.?wd activity 4wding 4.?wheel.?drive activity 4wding four.?wheel.?drive activity 4wding awd activity 4wding all.?wheel.?drive activity birding bird.?watching activity birding bird.?ing activity birding bird activity birding twitch.?ing activity birding twitch activity boating boating activity boating boat activity boating sail activity boating sailing activity boating sailed activity campfire camp.?fire activity campfire fire.?wood activity caving caving activity caving speleology activity cycling bike activity cycling biked activity cycling biking activity cycling cycle activity cycling cycled activity cycling cycling activity cycling mountain.?biking activity cycling mountain.?bike activity cycling mtb activity diving \\bdive\\b activity diving dived activity diving diving activity diving scuba activity dog dog(?!.fence) activity dolphin dolphin watching activity fishing fished activity fishing fishing activity geocaching geocache activity geocaching geocaching activity horse riding horse.?riding activity kayaking canoe activity kayaking canoed activity kayaking canoeing activity kayaking kayak activity kayaking kayaked activity kayaking kayaking activity orienteering orienteer activity orienteering orienteering activity orienteering orienteered activity rock climbing rock.?climbing activity snorkelling snorkel activity snorkelling snorkelled activity snorkelling snorkelling activity surfing surf activity surfing surfed activity surfing surfing activity swimming swam activity swimming swum activity swimming swim activity swimming swimming activity tennis tennis activity camping tent activity tour tour activity walking bush.?walk activity walking bush.?walked activity walking bush.?walking activity walking hike activity walking hiked activity walking hiking activity walking walk activity walking walked activity walking walking activity waterskiing water.?ski activity waterskiing water.?skiied activity waterskiing water.?skiing activity whale watching whale*?watching Table 8.3: Full list of activities and parks 8.3 R packages used Table 8.4: R (R Core Team 2019) packages used in the production of this report Package Citation base R Core Team (2019) bookdown Xie (2018) fs Hester and Wickham (2019) ggridges Wilke (2018) knitr Xie (2019) lubridate Spinu et al. (2018) readxl Wickham and Bryan (2019) rstan Guo et al. (2018) rstanarm Gabry and Goodrich (2018) tidytext Robinson and Silge (2018) tidyverse Wickham (2017) References "],
["references.html", "9 References", " 9 References "]
]
