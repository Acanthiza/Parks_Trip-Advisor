[
["introduction.html", "Analysis of Trip Advisor data relating to South Australian parks 1 Introduction", " Analysis of Trip Advisor data relating to South Australian parks Department for Environment and Water Wednesday, 29 May, 2019 1 Introduction DEW manages many parks across South Australia. Some of these parks have a ‘page’ on TripAdvisor. For example, there is a page for Ikara-Flinders Ranges National Park. DEW are interested to know what information is contained in TripAdvisor reviews. Specifically, the following questions were identified by the community engagement branch: Where are visitors from: Overall percentages – as in, of all the people who reviewed SA parks, 40 percent were Australian, 10 percent were English, 8 percent were American etc. By park percentages – as in, of all the people who reviewed Belair National Park, 40 percent were Australian, 10 percent were English, 8 percent were American etc. What gender are visitors: Overall percentages – as in, of all the people who reviewed SA parks, 45 percent were male and 55 percent were female By park percentages – as in, of all the people who reviewed Belair national park, 45 percent were male and 55 percent were female What ages are visitors? Overall By individual park When are reviews made? (As in, in which month is the quantity of reviews submitted to Trip Advisor the highest? In which month is the quantity of reviews submitted to Trip Advisor the lowest?) Overall By individual park How does seasonality affect park ratings? (As in, parks receive most positive ratings in December and most negative ratings in May) Overall By individual park Are males or females more likely to rate parks positively or negatively? Overall By individual park Which country/state is more likely to rate parks positively or negatively? Overall By individual park Which age is more likely to rate parks positively or negatively? Overall By individual park Other possible questions SA analysis – Adelaide vs regional views of parks Multiple park reviews from one user: Does reviewing more than one park lead to higher or lower ratings? What parks are visited by people who review more than one park? Can we get a sense of itinerary from international visitors? After an initial data exploration, these questions were treated as the following: What is the effect of age and gender on the rating given? What is the effect of the park visited on the rating given? What is the effect of the origin of a reviewer on the rating given? These three analyses answer most of the questions posed by the community engagement branch but do not always examine interations, such as, say, the interaction of age and park on stars. This was done as sample size was very small for some groups, especially for low stars. A further analysis of words used in the titles and reviews was also undertaken. "],
["methods.html", "2 Methods 2.1 Data source 2.2 Workflow", " 2 Methods 2.1 Data source Data were taken from Trip Advisor. The site is one of the most popular sources of reviews for hotels, restaurants, experiences, attractions and places such as parks. Trip Advisor features user-generated content with 315 million reviewers (active and inactive) and about 500 million reviews Wikipedia. For the purposes of this analysis, the search function in Trip Advisor was used to identify all parks, reserves and features in parks and reserves that have been reviewed. Some reviews were captured under a park name, such as “Flinders Chase National Park” and some were captured under a feature name, such as “Flinders Chase Visitor Centre”. In order to manage the scope of this analysis it was decided to collect reviews in the first instance for parks that were reviewed under their official park names. Where there was a park that is of importance to DEW that had reviews under a feature name rather than a park name, these reviews were also collected. For example, reviews were collected for “Waterfall Gully” rather than for “Cleland Conservation Park”. A further current limitation, imposed to manage scope, was exclusion of “iconic sites”. The reviews available were cross referenced against a list of priority parks that DEW has identified through the parks characterisation project to ensure that reviews were captured for all significant non-iconic sites. The web scraping software Octoparse was used to capture the following elements for analysis: Reviewer name Reviewer location (country, state and city) Reviewer age Reviewer gender Review date Review title Review text Review star rating Note that the web scraping software was able to effectively capture elements such as name, date, title, text and star rating, but that capturing the demographic information about the reviewers was a more difficult process. The demographic information is contained within “hover over” elements of the Trip Advisor web pages. Code was written to scrape these elements for the initial data scrape; manual cutting and pasting was used for scrape updates. It may be for this reason that most academic analysis of Trip Advisor reviews does not extend to considering demographic information and that this report may offer some new information about the utility of this data source. Once the data was captured it was cleaned so that it could be imported into SPSS for quantitative analysis and Nvivo for qualitative analysis. The cleaning included: Ensuring that each review was attached to a unique reviewer name Standardising place names to ensure that spellings were correct Allocating state and/or countries to reviewers who gave only partial location information such as city of residence Ensuring that the data set contained no blank cells Removing reviewers under 18 years old (Age field equal to ‘13-18’) 2.2 Workflow This data analysis and report writing was done in a single scripted workflow (script file: Report.Rmd using the programs ‘R’ and ‘R-studio’. R (R Core Team 2019) is an open-source platform which makes available a library of packages that can be used and modified as necessary. R-studio provides a range of user-friendly features to facilitate interaction with R. The packages used are listed in the appendix: R packages used Table 9.2. All data, code and outputs are stored in a version control system at Parks_Trip-Advisor. References "],
["data-exploration.html", "3 Data exploration 3.1 Summary 3.2 Missing data 3.3 Count of reviews", " 3 Data exploration 3.1 Summary Between 16/May/2004 and 02/November/2019 there were 3849 reviews on TripAdvisor meeting the criteria outline in the methods. 3.2 Missing data Some of the key data fields were left blank in many reviews. For example, 1714 (45%) reviews did not provide their gender and 1987 (52%) didn’t provide their age. Figure 3.1 shows the percentage of reviews that did not provide information against each field. Figure 3.1: A large proportion of reviews did not answer some questions, particularly Gender and Age 3.3 Count of reviews There are several variables in the data with relatively few levels: Age; City; Country; Gender; id; Month; Park; reviews; Stars; State; User; and Year. Figure 3.2 shows the most frequently occuring values in each of those variables. Figure 3.2: Most frequent values in each of the variables. Most reviews are from Adelaide based 50-64 year olds called Charmaine who visited Flinders Chase in January 2016 and gave it 5 stars "],
["age-and-gender.html", "4 Age and gender 4.1 Model 4.2 Model diagnostics 4.3 Model predictions", " 4 Age and gender 4.1 Model Trend through time (year) in stars given by age and gender of reviewers (and the interaction of age, gender and time) was analysed using a Bayesian binomial generalised linear mixed model. The analysis was run using the rstanarm package (Stan Development Team 2016) in R (R Core Team 2019). Month (of review), Park (visited by reviewer) and State (of origin of reviewer) were treated as random effects in the analysis. Each reviewer was then assumed to provide an independent data point for the analysis. A time field was generated as \\(time = min(Year) + (max(Year) - min(Year))/2\\). The model specification was: cbind(Y, 4 - Y) ~ Gender * Age * time + (1 | Month) + (1 | Park) + , (1 | State) where Y is Stars-1. 4.2 Model diagnostics Figure 4.1 shows that each of the chains used to estimate model parameters converged around similar values for each parameter. Figure 4.1: All chains converged around the same values for each of the model paramaters (first 10 shown here) Figure 4.2 provides further support for convergence of the chains as no values are markedly different to 1.0. Figure 4.2: Rhat values show no reason for concern Figure 4.3 shows how (a sample of) the model runs (in light blue) compare with the original data (shown in dark blue). Figure 4.3: The model runs under estimate four stars and over estimate three stars relative to the data Figure 4.4 shows how the mean and standard deviation of the model runs (in light blue) compare with that of the original data (in dark blue). Figure 4.4: Collectively the model runs do a reasonable job estimating the data 4.3 Model predictions In order to better understand how the data and resulting model are able to inform management, a number (4000) of simulations were made based on the model results (strictly, draws were made from the posterior predictive distribution). Each simulation generated a prediction based on a single draw of the model parameters from their predicted distributions. Table 4.1 shows a summary of these results. Table 4.1: Summary of model results Year Age Gender Mean Median and range in 90% credible intervals 2017 18-24 Male 3.63 4 (1 to 5) 2018 18-24 Female 4.77 5 (4 to 5) 2018 25-34 Female 4.80 5 (4 to 5) 2018 25-34 Male 4.76 5 (4 to 5) 2018 35-49 Female 4.65 5 (3 to 5) 2018 35-49 Male 4.64 5 (3 to 5) 2018 50-64 Female 4.67 5 (3 to 5) 2018 50-64 Male 4.67 5 (3 to 5) 2018 65+ Female 4.61 5 (3 to 5) 2018 65+ Male 4.49 5 (3 to 5) Figure 4.5 shows a plot of the model results. Overwhelmingly, reviewers give 5 stars, irrespective of age or gender. Figure 4.5: Model results - mean credible intervals. Most reviewers give 5 stars irrespective of age or gender. The lower 95% credible intervals go to three stars in almost every case - i.e. more than 95% of responses are three stars or more. Only for 18-24 year old males in 2015 do the 95% credible intervals go to 1 star References "],
["park.html", "5 Park 5.1 Model 5.2 Model diagnostics 5.3 Model predictions", " 5 Park 5.1 Model Trend through time (year) in stars given to a park (and the interaction of park and time) was analysed using a Bayesian binomial generalised linear mixed model. The analysis was run using the rstanarm package (Stan Development Team 2016) in R (R Core Team 2019). Age, gender and origin of reviewer were treated as random effects in the analysis. Each reviewer was then assumed to provide an independent data point for the analysis. A time field was generated as \\(time = min(Year) + (max(Year) - min(Year))/2\\). The model specification was: cbind(Y, 4 - Y) ~ time * Park + (1 | Age) + (1 | Gender) + (1 | , State) where Y is Stars-1. 5.2 Model diagnostics Figure 5.1 shows that each of the chains used to estimate model parameters converged around similar values for each parameter. Figure 5.1: All chains converged around the same values for each of the model paramaters (first 10 shown here) Figure 5.2 provides further support for convergence of the chains as no values are markedly different to 1.0. Figure 5.2: Rhat values show no reason for concern Figure 5.3 shows how (a sample of) the model runs (in light blue) compare with the original data (shown in dark blue). Figure 5.3: The model runs under estimate four stars and over estimate three stars relative to the data Figure 5.4 shows how the mean and standard deviation of the model runs (in light blue) compare with that of the original data (in dark blue). Figure 5.4: Collectively the model runs do a reasonable job estimating the data 5.3 Model predictions In order to better understand how the data and resulting model are able to inform management, a number (4000) of simulations were made based on the model results (strictly, draws were made from the posterior predictive distribution). Each simulation generated a prediction based on a single draw of the model parameters from their predicted distributions. Table 5.1 shows a summary of these results. Table 5.1: Summary of model results for the last year. Point Labatt Conservation Park, Granite Island and Belair National Park have the lowest stars (based on mean credible estimates) Park Year Mean Median and range in 90% credible intervals Flinders Ranges National Park 2018 4.82 5 (4 to 5) Flinders Chase National Park 2018 4.77 5 (4 to 5) Hallett Cove Conservation Park 2018 4.71 5 (3 to 5) Morialta Conservation Park 2018 4.65 5 (3 to 5) Innes National Park 2018 4.63 5 (3 to 5) Breakaways Conservation Park 2018 4.57 5 (3 to 5) Waterfall Gully 2018 4.48 5 (3 to 5) Other 2018 4.43 5 (3 to 5) Point Labatt Conservation Park 2018 4.36 5 (2 to 5) Granite Island 2018 4.34 5 (2 to 5) Belair National Park 2018 4.30 5 (2 to 5) Figure 5.5: Model results - mean credible intervals. Belair and Point Labatt both seem to be getting increasingly negative reviews - although the mean credible estimate for both remains above 4 stars currently References "],
["origin.html", "6 Origin 6.1 Model 6.2 Model diagnostics 6.3 Model predictions", " 6 Origin 6.1 Model Trend through time (year) in stars given by the origin of reviewers (and the interaction of origin and time) was analysed using a Bayesian binomial generalised linear mixed model. The analysis was run using the rstanarm package (Stan Development Team 2016) in R (R Core Team 2019). Age and gender of the reviewer and the park visisted were treated as random effects in the analysis. Each reviewer was then assumed to provide an independent data point for the analysis. A time field was generated as \\(time = min(Year) + (max(Year) - min(Year))/2\\). The model specification was: cbind(Y, 4 - Y) ~ time * State + (1 | Age) + (1 | Gender) + (1 | , Park) where Y is Stars-1. 6.2 Model diagnostics Figure 6.1 shows that each of the chains used to estimate model parameters converged around similar values for each parameter. Figure 6.1: All chains converged around the same values for each of the model paramaters (first 10 shown here) Figure 6.2 provides further support for convergence of the chains as no values are markedly different to 1.0. Figure 6.2: Rhat values show no reason for concern Figure 6.3 shows how (a sample of) the model runs (in light blue) compare with the original data (shown in dark blue). Figure 6.3: The model runs under estimate four stars and over estimate three stars relative to the data Figure 6.4 shows how the mean and standard deviation of the model runs (in light blue) compare with that of the original data (in dark blue). Figure 6.4: Collectively the model runs do a reasonable job estimating the data 6.3 Model predictions In order to better understand how the data and resulting model are able to inform management, a number (4000) of simulations were made based on the model results (strictly, draws were made from the posterior predictive distribution). Each simulation generated a prediction based on a single draw of the model parameters from their predicted distributions. Table 6.1 shows a summary of these results. Table 6.1: Summary of model results for the last year. California and Queensland give the highest stars (based on mean credible estimates) State Year Mean Median and range in 90% credible intervals California 2017 4.91 5 (4 to 5) Queensland 2018 4.72 5 (3 to 5) New South Wales 2018 4.68 5 (3 to 5) Other 2018 4.66 5 (3 to 5) Australian Capital Territory 2018 4.59 5 (3 to 5) Victoria 2018 4.59 5 (3 to 5) England 2018 4.57 5 (3 to 5) North Island 2018 4.54 5 (3 to 5) South Australia 2018 4.54 5 (3 to 5) Western Australia 2018 4.52 5 (3 to 5) Singapore 2018 4.33 5 (2 to 5) Figure 6.5: Model results - mean credible intervals. California and the North Island of New Zealand both appear to have increased the stars they give in reviews through time, however the total number of reviews are low in each case so this result should be treated cautiously. There is very little trend in stars given by origin of reviewers for other origins References "],
["word-analysis.html", "7 Word analysis 7.1 Overall sentiment 7.2 By park sentiment 7.3 Activities", " 7 Word analysis 7.1 Overall sentiment Using the tidytext package (Robinson and Silge 2018), the text within the character fields Title and Review were analysed. Some words were replaced with a synonym (Appendix Table 9.1). This includes ‘lumping’ words such as, say, echidna into wildlife. The following words were reclassified as neutral from negative sentiment as they were overwhelmingly not used in a negative manner: cave; challenging; cold; crashing; desert; dirt; downhill; falls; miss; remarkable; rocky; ruins; shady; steep; unbelievable; unexpected; unusual; wedge; and wild. The following words were removed from the analysis as they refer to park or place names, and occur frequently, but do not add much to the analysis: adelaide; arch; chase; coffin; coober; flinders; granite; gully; harbor; harbour; island; kangaroo; ki; lofty; morialta; mount; mt; national; park; pedy; pound; ranges; rocks; victor; and wilpena. Figure 7.1 shows the ten most common positive, negative and neutral words given in the Title field. The presence of worth in this list suggested that reviewers thought that the positive sentiments they expressed came at a cost (perhaps time and/or distance). A random sample of contexts in which worth occured: “Well Worth a Visit” Worth the trip to Flinders! “Well worth seeing” “Worth the trip” Worth a Visit Figure 7.2 shows the ten most common positive, negative and neutral words given in the Review field. Again, the most frequently occuring words are positive or neutral. Also, worth occurs frequently again, but so does easy. A random sample of contexts in which easy occured: The roads here a very well maintained, and cleared regularly. The park café was friendly and well-stocked. A fabulous coffee set us off on our journey. The sights of Admiral’s Arch and Remarkable Rocks are simply awesome. Set up well for easy access. Waterfall Gully is a beautiful place and also very popular. It was really difficult to find a parking space on a Sunday morning. It was an easy walk to the waterfall. It is a beautiful sight. Good place to start a hike too. Surprisingly fast to get to by car, no good connections by public transportation though. These challenging and well maintained mountain bike trails were a great discovery! As a novice I found these trails tough going but well worth the effort. They start at an intermediate level. For easy trails you need to head down to the nearby Melrose Showgrounds. The local bike shop is simply brilliant and provides quality bike hire, gear, maps and even coffee! good short and longer walks ranging from easy to moderate/hard. great views and waterfalls in winter Let me start by saying the flinders rangers are beautiful, I have visited the area a few times and love the views. This was my 1st time visiting Wilpena pound via the visitor centre at the resort. We were keen to do a walk and check the views of the pound. I asked at the visitor centre how long are the walks, I ask as I have a child still recovering his strength from chemotherapy treatment (I did not disclose that). I was told it is an easy 2km walk to the pound. That was achievable, however the more I read the information signs along the way the walk was much longer, about a 6.6km return. It is 2km walk to the entrance of the pound, then onwards. We made it to the Homestead look out, and in the words of my son, it was not worth the walk. I take responsibility for not doing my homework on the distances, however I would have thought that information would have been made clear when I asked. If you love your bush walks and hikes, there are heaps here to do. Figure 7.1: Titles had words with positive sentiment much more frequently than words with negative sentiment Figure 7.2: Reviews used words with positive sentiment more frequently than words with negative sentiment 7.2 By park sentiment Figure 7.3 shows, by park, the five most common positive, negative and neutral words given in the Title field. The lowest frequency at which nature occurs is third. A random sample of contexts in which nature occurs: “Wonderful glimpse into rugged South Australian nature” “Mother nature at her best” great leisurely walk with natural and manmade beauty–and a sunset miracle of nature-Shearwaters returning “Good hikes and nature” A piece of nature near the city that is worth the hike Figure 7.4 shows, by park, the five most common positive, negative and neutral words given in the Review field. Each park had hard in the negative words, followed by difficult which occured in most parks. Some examples of the context in which hard occurs: long drive from the centre of Kingscote but well worth the effort with many other attractions close by such as lighthouse, National park and beaches. The parking is good and the short walk not hard. an amazing place that is really popular but people sort of get absorbed into the surroundings. Great place to go for a walk, have a coffee and enjoy fresh air, no fee to pay to get in but it is a little bit hard to get parking so be patient. We went there on Friday after lunch , car park was ok but on the week end I can’t imagine how hard it would be to find a place. Anyway , you just can walk ( hard walk but so nice ) to mount lofty , around 4km but you have different way to go there , and even if you don’t want walk so far just walk 500m up to see the waterfall and you can also go on a top ( 5mins walk). Just get a cold water bottle and good shoes :) Figure 7.3: Top ten words in the title text for each sentiment class (positive, negative and neutral) for the parks with the most reviews Figure 7.4: Top ten words in the review text for each sentiment class (positive, negative and neutral) for the parks with the most reviews 7.3 Activities Figure 7.5 shows how frequently various activities were mentioned in the Review field. This information is essentially the same as in Figure 7.2 but with a focus only on activities. Figure 7.6 shows the frequency with which activities are mentioned in the Review field for the most reviewed parks. Often reviewers mention things done outside the park in their reviews. For example, the reviews for Granite Island that mentioned camping gave lots of information about the area around that park: We had initially been disappointed to find out that the penguin population was so small that we wouldn’t be able to see any, but decided to visit the Island anyways. We enjoyed our stroll and the cool granite structures. Our favourite part of visiting Victor Harbour was the hike up the Bluffs and then along the Petrol Cove Path. We spent the night camping in Waitpinga and that was our highlight of the trip. The beach was amazing and so was the hike along the Heysen Trail. We’d strongly advise anyone visiting this area to include some of these bush walks in their visit and next time we go back we’d take more time to do more of this Victor Harbour and the Fleurieu Peninsula. Victor Harbor is situated approx 80kms south of Adelaide, the drive takes around 80 minutes depending whether you want to stop at Mclaren Valley. We stayed at the Whalers Inn situated just on the outskirts of Victor Harbor. (Read review) and had all intentions of visiting Kangaroo Island. What is amazing about this area is the huge diversity of landscapes and attractions, which can cause a deviation or detour from your original itinerary. Hence, we never got to see Kangaroo Island, as we found the whole region of the Fleurieu Peninsula absolutely fascinating, stunning and spectacular with dramatic scenery. The natural wilderness mixed with pristine rugged coastline and beaches, truly makes this region Australia’s best natural asset. Victor Harbor is nestled by the sea, with lovely colonial heritage buildings and sites. The town is very quaint with some great old Australian pubs and Inns. There are plenty of restaurants, cafes and shops to keep you entertained. You can take a Heritage walking trial tour and learn the history of buildings like the Old Custom and Stationmaster house. The best thing to do is walk across or catch the horse-drawn wagon across to Granite Island and see the colony of little penguins. The best time to see the penguins is in the early evening around 7pm, as the penguins return home from sea to feed their chicks. (Make sure you take some warm clothes, it…Victor Harbour and the Fleurieu Peninsula. Victor Harbor is situated approx 80kms south of Adelaide, the drive takes around 80 minutes depending whether you want to stop at Mclaren Valley. We stayed at the Whalers Inn situated just on the outskirts of Victor Harbor. (Read review) and had all intentions of visiting Kangaroo Island. What is amazing about this area is the huge diversity of landscapes and attractions, which can cause a deviation or detour from your original itinerary. Hence, we never got to see Kangaroo Island, as we found the whole region of the Fleurieu Peninsula absolutely fascinating, stunning and spectacular with dramatic scenery. The natural wilderness mixed with pristine rugged coastline and beaches, truly makes this region Australia’s best natural asset. Victor Harbor is nestled by the sea, with lovely colonial heritage buildings and sites. The town is very quaint with some great old Australian pubs and Inns. There are plenty of restaurants, cafes and shops to keep you entertained. You can take a Heritage walking trial tour and learn the history of buildings like the Old Custom and Stationmaster house. The best thing to do is walk across or catch the horse-drawn wagon across to Granite Island and see the colony of little penguins. The best time to see the penguins is in the early evening around 7pm, as the penguins return home from sea to feed their chicks. (Make sure you take some warm clothes, it can get very chilly with the sea winds.) If thinking of staying at Cape Jervis before heading to Kangaroo Island then disregard this idea. Victor Harbour is a lovely seaside town and far more appealing and interesting; Whaler’s Inn is approx 30 minutes drive away from Cape Jervis and a far better choice to be positioned. What to do: Walk across to Granite Island and see the penguins at dusk. Visit the towns of Goolwa, Port Elliot, Hindmarsh Island, and Coorong National Park and see the Murray River Mouth. For some awesome scenery take a walk on the “Heysen Trail” which can be connected to just past the Bluff or at Parsons beach or Newland Headlands.(A must do). You can walk this track to Cape Jervis but it takes a couple of days, camping areas are available for keen bushwalkers. Another walk is from Victor Harbor to Port Elliot along the beach. (7kms). All maps can be obtained at the Information Centre. Follow all the tourist brown signs and get lost in the beauty exploring this gorgeous region. From Cape Jervis drive the coastal road back to Adelaide and see some lovely seaside towns. More Figure 7.5: nature, walk and wildlife are by far the most popular activities mentioned in reviews Figure 7.6: The reviews provided for a park often spill over into surrounding activites. This explains, say, camping being an activity mentioned for Granite Island References "],
["discussion.html", "8 Discussion 8.1 Questions 8.2 Words used in reviews", " 8 Discussion 8.1 Questions It is now possible to answer the questions posed at the start with respect to the TripAdvisor data. 8.1.1 What is the effect of age and gender on the rating given? There is very little effect of age and gender on stars. 18-24 year old males had the lowest mean credible estimate for stars but this was still a relatively healthy 3.63 stars. 8.1.2 What is the effect of the park visited on the rating given? There is little effect of park on the rating given. In the last year there was only 0.52 stars difference between the maximum and minimum mean credible estimate for stars given to parks in the dataset. This is only 10.4% of the possible range of 1 to 5. 8.1.3 What is the effect of the origin of a reviewer on the rating given? There is very little effect of the origin of a reviewer on the rating given. In the last year, there was only 0.39 stars or 7.8% of the possible difference. 8.1.4 Summary The TripAdvisor data has little resolution in stars given for the attributes available for analysis. Most reviewers give South Australian DEW managed parks very good reviews - roughly 4.5 stars on average. 8.2 Words used in reviews As for the stars analysis, the word analysis showed overwhelmingly positive words were used to describe both overall parks (Figures 7.1 &amp; 7.2) or for specific parks (Figures 7.3 &amp; 7.4). Reviewers most frequently mention nature; walk; and wildlife in their reviews along with positive words such as amazing; beautiful; easy; enjoy; and worth. "],
["appendix.html", "9 Appendix 9.1 Changed words 9.2 R packages used", " 9 Appendix 9.1 Changed words Table 9.1: Words that were changed to a synonym before further analysis word changed disappointing dissapoint disappointed dissapoint disappointment dissapoint colours colour color colour beauty beautiful enjoyed enjoy loved love sadly sad difficulty difficult crowded crowd limits limit beaches beach cycling cycle cycled cycle cyclists cycle riding cycle rides cycle mtb cycle bike cycle rode cycle walking walk walked walk walks walk stroll walk strolling walk hiking walk hiked walk hike walk camping camp camped camp driving drive drove drive penguin wildlife penguins wildlife fur wildlife seal wildlife seals wildlife koala wildlife koalas wildlife kangaroos wildlife echidna wildlife platypus wildlife bird wildlife birds wildlife wallabies wildlife emu wildlife emus wildlife animals wildlife lions wildlife sealions wildlife landscape nature view nature views nature scenery nature scenic nature natural nature breakaways nature remarkable nature admirals nature waterfall nature falls nature waterfalls nature lighthouse heritage ruin heritage 9.2 R packages used Table 9.2: R (R Core Team 2019) packages used in the production of this report Package Citation base R Core Team (2019) bookdown Xie (2018) fs Hester and Wickham (2019) ggridges Wilke (2018) knitr Xie (2019) lubridate Spinu et al. (2018) readxl Wickham and Bryan (2019) rstan Guo et al. (2018) rstanarm Gabry and Goodrich (2018) tidytext Robinson and Silge (2018) tidyverse Wickham (2017) References "],
["references.html", "10 References", " 10 References "]
]
